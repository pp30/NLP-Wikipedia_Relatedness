{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "retrofit.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "id1P18PIQpcl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "'''\n",
        "Utilized code from https://github.com/mfaruqui/retrofitting for implementation\n",
        "Reference paper: https://arxiv.org/abs/1411.4166 by Faruqui et al\n",
        "\n",
        "'''"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "34e5LSQ2B9i8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "fe52c440-510e-46bd-b33d-af8d03b3beed"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/gdrive')\n",
        "%cd /gdrive"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n",
            "/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dL9BI3svCxQy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "outputId": "46a16fd5-605d-48ac-eef9-4cc26d92e570"
      },
      "source": [
        "import os\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "import numpy as np\n",
        "os.chdir('/gdrive/My Drive/NLP_Project_Programs/Paper_Implementation')\n",
        "os.listdir()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Vector Representation of Words',\n",
              " 'lexicons',\n",
              " '.gitignore',\n",
              " 'README.md',\n",
              " 'sample_vec.txt',\n",
              " 'LICENSE',\n",
              " 'retrofit.py',\n",
              " 'out_vec.txt',\n",
              " 'Evaluation_Benchmarks',\n",
              " 'retrofit.ipynb',\n",
              " 'Untitled0.ipynb']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p_s3QF6zCnnU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import argparse\n",
        "import gzip\n",
        "import math\n",
        "import numpy\n",
        "import re\n",
        "import sys\n",
        "#pawann helloooooooooo    \n",
        "from copy import deepcopy\n",
        "\n",
        "isNumber = re.compile(r'\\d+.*')\n",
        "def norm_word(word):\n",
        "  if isNumber.search(word.lower()):\n",
        "    return '---num---'\n",
        "  elif re.sub(r'\\W+', '', word) == '':\n",
        "    return '---punc---'\n",
        "  else:\n",
        "    return word.lower()\n",
        "\n",
        "''' Read all the word vectors and normalize them '''\n",
        "def read_word_vecs(filename):\n",
        "  wordVectors = {}\n",
        "  if filename.endswith('.gz'): fileObject = gzip.open(filename, 'r')\n",
        "  else: fileObject = open(filename, 'r')\n",
        "  \n",
        "  for line in fileObject:\n",
        "    line = line.strip().lower()\n",
        "    word = line.split()[0]\n",
        "    wordVectors[word] = numpy.zeros(len(line.split())-1, dtype=float)\n",
        "    for index, vecVal in enumerate(line.split()[1:]):\n",
        "      wordVectors[word][index] = float(vecVal)\n",
        "    ''' normalize weight vector '''\n",
        "    wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
        "    \n",
        "  sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
        "  return wordVectors\n",
        "    \n",
        "''' Read the PPDB word relations as a dictionary '''\n",
        "def read_lexicon(filename):\n",
        "  lexicon = {}\n",
        "  for line in open(filename, 'r', encoding=\"utf8\"):\n",
        "    words = line.lower().strip().split()\n",
        "    lexicon[norm_word(words[0])] = [norm_word(word) for word in words[1:]]\n",
        "  return lexicon\n",
        "\n",
        "''' Write word vectors to file '''\n",
        "def print_word_vecs(wordVectors, outFileName):\n",
        "  sys.stderr.write('\\nWriting down the vectors in '+outFileName+'\\n')\n",
        "  outFile = open(outFileName, 'w')  \n",
        "  for word, values in wordVectors.items():\n",
        "    outFile.write(word+' ')\n",
        "    for val in wordVectors[word]:\n",
        "      outFile.write('%.4f' %(val)+' ')\n",
        "    outFile.write('\\n')      \n",
        "  outFile.close()\n",
        "\n",
        "''' Retrofit word vectors to a lexicon '''\n",
        "def retrofit(wordVecs, lexicon, numIters):\n",
        "  newWordVecs = deepcopy(wordVecs)\n",
        "  wvVocab = set(newWordVecs.keys())\n",
        "  loopVocab = wvVocab.intersection(set(lexicon.keys()))\n",
        "  for it in range(numIters):\n",
        "    # loop through every node also in ontology (else just use data estimate)\n",
        "    for word in loopVocab:\n",
        "      wordNeighbours = set(lexicon[word]).intersection(wvVocab)\n",
        "      numNeighbours = len(wordNeighbours)\n",
        "      #no neighbours, pass - use data estimate\n",
        "      if numNeighbours == 0:\n",
        "        continue\n",
        "      # the weight of the data estimate if the number of neighbours\n",
        "      newVec = numNeighbours * wordVecs[word]\n",
        "      # loop over neighbours and add to new vector (currently with weight 1)\n",
        "      for ppWord in wordNeighbours:\n",
        "        newVec += newWordVecs[ppWord]\n",
        "      newWordVecs[word] = newVec/(2*numNeighbours)\n",
        "  return newWordVecs\n",
        "  \n",
        "# if __name__=='__main__':\n",
        "\n",
        "#   parser = argparse.ArgumentParser()\n",
        "#   parser.add_argument(\"-i\", \"--input\", type=str, default=None, help=\"Input word vecs\")\n",
        "#   parser.add_argument(\"-l\", \"--lexicon\", type=str, default=None, help=\"Lexicon file name\")\n",
        "#   parser.add_argument(\"-o\", \"--output\", type=str, help=\"Output word vecs\")\n",
        "#   parser.add_argument(\"-n\", \"--numiter\", type=int, default=10, help=\"Num iterations\")\n",
        "#   args = parser.parse_args()\n",
        "\n",
        "  # wordVecs = read_word_vecs(args.input)\n",
        "  # lexicon = read_lexicon(args.lexicon)\n",
        "  # numIter = int(args.numiter)\n",
        "  # outFileName = args.output\n",
        "  \n",
        "  # ''' Enrich the word vectors using ppdb and print the enriched vectors '''\n",
        "  # print_word_vecs(retrofit(wordVecs, lexicon, numIter), outFileName) \n",
        "\n",
        "\n",
        "input_vector = 'sample_vec.txt'\n",
        "lexicon = 'lexicons/ppdb-xl.txt'\n",
        "numiter = 10\n",
        "output = 'out_vec.txt'\n",
        "\n",
        "wordVecs = read_word_vecs(input_vector)\n",
        "lexicon = read_lexicon(lexicon)\n",
        "numIter = int(numiter)\n",
        "outFileName = output\n",
        "\n",
        "''' Enrich the word vectors using ppdb and print the enriched vectors '''\n",
        "print_word_vecs(retrofit(wordVecs, lexicon, numIter), outFileName) "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ygxg87m6Br15",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_1_word_vecs(path):\n",
        "  '''\n",
        "  Add code here...\n",
        "  '''\n",
        "  return None\n",
        "\n",
        "path = 'Vector Representation of Words/1/...'\n",
        "process_1_word_vecs(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICprXX--E-sV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_2_word_vecs(path):\n",
        "  model = KeyedVectors.load_word2vec_format(path, binary=True)\n",
        "  print('Done step 1')\n",
        "  # 3000001 lines. 1st line is just description and to be ignored.\n",
        "  model.save_word2vec_format('/'.join(path.split('/')[:-1])+'/GoogleNews-vectors-negative300.txt', binary=False)\n",
        "  print('Done step 2')\n",
        "  return None\n",
        "\n",
        "path = 'Vector Representation of Words/2/GoogleNews-vectors-negative300.bin'\n",
        "process_2_word_vecs(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NWHoKQqp4z82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_3_word_vecs(path_vocab, path_wordvectors):\n",
        "  vocabObject = open(path_vocab, 'r')\n",
        "  wordvectorsObject = open(path_wordvectors, 'r')\n",
        "\n",
        "  outFileName = '/'.join(path_wordvectors.split('/')[:-1]) + '/3_word_vectors.txt'\n",
        "\n",
        "  outFile = open(outFileName, 'w')  \n",
        "  for word, vector in zip(vocabObject,wordvectorsObject):\n",
        "    outFile.write(word.strip()+' ')\n",
        "    for val in vector.strip().split():\n",
        "      outFile.write('%.6f' %(float(val))+' ')\n",
        "    outFile.write('\\n')\n",
        "  outFile.close()\n",
        "\n",
        "  return None\n",
        "\n",
        "path_vocab = 'Vector Representation of Words/3/vocab.txt'\n",
        "path_wordvectors = 'Vector Representation of Words/3/wordVectors.txt'\n",
        "process_3_word_vecs(path_vocab, path_wordvectors)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7q9MYmwOB2OO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def process_4_word_vecs(path):\n",
        "  '''\n",
        "  Add code here...\n",
        "  '''\n",
        "  return None\n",
        "\n",
        "path = 'Vector Representation of Words/4/...'\n",
        "process_4_word_vecs(path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9lGphmwazEBN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "temp = []\n",
        "while True:\n",
        "  temp.append('aaaaaaaaaaaaabbbbbbbbbbbbbbbcccccccccccc')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dcNUuIFY9sKk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "path_vocab = 'Vector Representation of Words/2/GoogleNews-vectors-negative300.txt'\n",
        "\n",
        "vocabObject = open(path_vocab, 'r')\n",
        "# wordvectorsObject = open(path_wordvectors, 'r')\n",
        "# with open(path_vocab, \"r+\") as f:\n",
        "#     d = f.readlines()\n",
        "#     f.seek(0)\n",
        "#     for index, i in enumerate(d[1:]):\n",
        "#       if index%10000==0:print('->', index,'/ 3000000')\n",
        "#       f.write(i)\n",
        "#     f.truncate()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "304kkhQs-Jg-",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 437
        },
        "outputId": "b944960c-edf5-4fa3-c728-d5c4f5074419"
      },
      "source": [
        "for index, line in enumerate(vocabObject):\n",
        "  print(line, len(line.split()))\n",
        "  if index ==10:break"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "</s> 0.0011291504 -0.00089645386 0.00031852722 0.0015335083 0.0011062622 -0.0014038086 -3.0517578e-05 -0.0004196167 -0.0005760193 0.0010757446 -0.0010223389 -0.00061798096 -0.00075531006 0.0014038086 -0.0016403198 -0.00063323975 0.0016326904 -0.0010070801 -0.0012664795 0.00065231323 -0.000415802 -0.0010757446 0.0015258789 -0.0002746582 0.00014019012 0.0015716553 0.0013580322 -0.000831604 -0.0014038086 0.0015792847 0.00025367737 -0.0007324219 -0.00010538101 -0.0011672974 0.0015792847 0.00065612793 -0.0006599426 2.9206276e-06 0.0011291504 0.0004272461 -0.00037002563 -0.0011520386 0.0012664795 -3.516674e-06 0.00026512146 -0.00040245056 0.0001411438 -3.361702e-05 0.00075912476 -0.0005187988 -7.104874e-05 0.00060272217 -0.00050735474 -0.001625061 -0.00043678284 -0.0009918213 -0.0012207031 -0.00032234192 6.866455e-05 -0.0011672974 -0.00051116943 0.001411438 0.00033569336 -0.0004749298 -0.001373291 0.00036621094 -0.0014419556 -0.00060653687 0.0008010864 0.0011291504 -0.0008354187 -0.001159668 0.00091552734 0.0005226135 -0.00032806396 0.0015945435 -0.0015792847 -0.0003566742 0.00049591064 0.0010147095 -0.0010986328 -0.00016593933 -0.00014209747 -0.00026130676 0.0012588501 3.862381e-05 0.00016880035 -0.0010299683 0.0016098022 0.00062942505 0.00041770935 -0.0013504028 0.0003490448 0.0011444092 -0.0012054443 -0.0011825562 0.0009498596 6.055832e-05 1.0728836e-05 -0.000667572 0.0012435913 0.0006904602 5.555153e-05 -0.0008621216 -0.0011672974 0.0012130737 -0.0008049011 -0.0008773804 0.00022792816 -0.00039672852 -0.0008583069 0.00028800964 -0.0015869141 0.00048446655 -0.001121521 1.9669533e-06 -0.00037956238 0.000705719 -0.0015869141 0.001625061 0.0015563965 -0.0004310608 0.0009841919 0.00090408325 -0.0013961792 0.0012054443 -0.0007019043 0.0002708435 -0.0012359619 0.0006904602 -0.0008430481 0.0013427734 -0.0014343262 -0.0006713867 0.0015487671 -0.0010986328 0.0011901855 -0.0014266968 -0.0006828308 -0.00078582764 0.00048065186 0.0004081726 -0.00063705444 0.0001449585 -0.0009765625 0.001449585 8.456409e-07 -0.001663208 -0.00032806396 0.00062942505 -0.0014343262 -0.0003414154 0.0011520386 -0.0005302429 -0.0004711151 -0.0008506775 -0.0013809204 -0.0012435913 -0.0013275146 0.0010757446 0.0013198853 -0.00030326843 -3.7431717e-05 0.0011825562 -0.0013580322 -0.001045227 5.6743622e-05 -0.0010147095 0.00043296814 -0.0015716553 -9.10759e-05 0.0010604858 -0.00060272217 -0.0015335083 -0.0015335083 0.000541687 0.001335144 0.0004119873 -0.00031089783 0.00017642975 -0.0001373291 -0.0006980896 -0.0008621216 -0.001083374 -2.9802322e-05 0.0008010864 0.0006790161 0.00033569336 -0.0013885498 0.0013504028 0.00023460388 -0.001335144 -0.0008735657 -0.00074386597 0.001083374 6.055832e-05 -0.0012664795 0.0011901855 -0.00062179565 1.359731e-07 0.0012741089 -0.0009841919 -0.0015487671 0.0015563965 -0.0013122559 -0.00079345703 0.0015335083 0.0012969971 -0.00018024445 0.00091934204 0.0012054443 0.00077056885 -0.0016555786 0.00077056885 0.001449585 -0.0013046265 0.00061035156 0.0006599426 0.0012588501 0.0014190674 -0.0012207031 -0.0015106201 0.0011291504 0.0013427734 0.001663208 -0.0005722046 -0.0005569458 0.00039863586 -0.0002708435 0.00049591064 0.0016098022 -0.000705719 0.00062561035 -0.0009765625 -0.00018978119 9.536743e-05 -0.0005187988 -0.0002040863 -0.0008277893 -0.00012302399 0.00076293945 0.00032234192 -0.0012435913 0.0009918213 0.0010604858 -0.001411438 9.679794e-05 -0.0015563965 0.0002193451 -5.531311e-05 -0.00091171265 -0.0014877319 0.0013656616 -0.0008430481 -0.0004196167 0.00032424927 -0.0010070801 0.00012588501 -0.00045585632 0.00019264221 -0.00026893616 0.0014953613 -0.0015869141 0.0005912781 -0.0014648438 0.0009651184 -0.0012817383 0.0016021729 0.0010910034 -0.0013122559 0.0010910034 -0.00051116943 0.0003452301 0.001045227 -0.00020694733 0.00090408325 0.000667572 0.0011062622 -0.0008735657 -0.00037574768 -0.00025749207 -9.1552734e-05 0.0014343262 -0.0011825562 -8.72612e-05 0.0013275146 -0.00015830994 0.0012893677 -0.0009841919 -0.0005493164 -0.0015487671 0.001373291 -6.0796738e-05 -0.0008239746 0.0013275146 0.001159668 0.0005683899 -0.0015640259 -0.00012302399 -8.6307526e-05\n",
            " 301\n",
            "in 0.0703125 0.08691406 0.087890625 0.0625 0.06933594 -0.10888672 -0.08154297 -0.15429688 0.020751953 0.13183594 -0.11376953 -0.037353516 0.06933594 0.078125 -0.103027344 -0.09765625 0.044189453 0.10253906 -0.060791016 -0.036132812 -0.045410156 0.04736328 -0.12060547 -0.063964844 0.0022583008 0.037109375 -0.0029144287 0.11767578 0.061767578 0.063964844 0.08105469 -0.068847656 -0.021362305 0.05517578 -0.08544922 0.068847656 -0.12792969 -0.033203125 0.09863281 0.17578125 0.110839844 -0.03466797 -0.04711914 -0.008483887 0.035888672 0.103027344 0.026977539 -0.028686523 -0.005126953 0.10644531 0.059814453 0.09423828 0.033691406 -0.02709961 -0.09423828 0.0010299683 -0.048339844 0.034423828 0.08105469 -0.11328125 -0.08886719 0.035888672 -0.14550781 -0.24414062 -0.061523438 0.052978516 0.056884766 0.1796875 0.061035156 0.08691406 0.12402344 -0.040283203 0.022583008 0.17773438 -0.029663086 -0.029663086 0.1171875 0.03112793 -0.096191406 0.06640625 0.004699707 -0.080078125 0.06298828 -0.020629883 -0.0546875 -0.13574219 -0.06347656 0.083496094 -0.063964844 0.021484375 0.07714844 -0.037109375 -0.033691406 -0.18359375 -0.072753906 0.01586914 0.09326172 -0.061523438 -0.014221191 -0.0034484863 0.011108398 -0.15820312 -0.017089844 0.0061950684 -0.008728027 -0.080566406 -0.015258789 -0.087890625 0.003479004 -0.016113281 -0.012329102 0.09765625 -0.13964844 -0.0859375 -0.026855469 0.053955078 0.1328125 0.11279297 0.12109375 0.08544922 -0.0071105957 0.044677734 -0.14550781 -0.0032043457 -0.11767578 -0.06542969 0.07128906 -0.09423828 -0.030273438 0.12011719 0.080078125 -0.09472656 -0.16210938 -0.07763672 0.021240234 -0.08154297 0.0039367676 -0.15722656 -0.09814453 0.039794922 0.03930664 -0.009094238 0.103027344 0.067871094 -0.04272461 0.06347656 -0.049072266 0.020874023 -0.16699219 0.09326172 0.09375 0.006866455 0.053710938 0.052490234 -0.024414062 -0.032470703 -0.061523438 -0.005554199 0.096191406 0.037841797 0.012207031 -0.043945312 -0.0074768066 0.10546875 0.020385742 0.14550781 0.08203125 0.0057678223 0.0045776367 -0.09277344 -0.13867188 -0.057373047 -0.051513672 -0.13085938 -0.13964844 -0.020507812 -0.02709961 0.032714844 0.10498047 -0.0023345947 -0.022583008 0.00050354004 -0.110839844 0.08496094 -0.12988281 -0.017456055 -0.00035858154 0.107910156 0.08886719 0.044677734 0.025146484 0.023803711 0.08105469 0.02368164 -0.10986328 0.0053710938 -0.017700195 -0.033935547 -0.032958984 -0.1640625 0.095703125 -0.018310547 0.0053100586 -0.034423828 -0.044189453 -0.06640625 -0.017944336 -0.029663086 -0.007598877 -0.05126953 -0.05419922 0.08935547 -0.071777344 0.015258789 -0.08251953 -0.03173828 0.03564453 -0.021240234 -0.059326172 -0.013061523 0.046875 0.023071289 0.020996094 -0.07861328 -0.008056641 0.01953125 -0.005554199 0.041503906 0.027832031 0.01361084 0.03466797 -0.18261719 0.12011719 0.07421875 -0.041015625 -0.0099487305 0.04296875 -0.007293701 0.123046875 0.057617188 -0.053466797 -0.032226562 -0.009094238 -0.04663086 0.043945312 -0.05078125 0.068847656 0.0029907227 -0.004180908 -0.044189453 0.07373047 -0.012756348 0.06738281 0.006286621 0.07519531 -0.037841797 0.0048828125 0.044677734 -0.06738281 0.00970459 0.0047302246 0.020507812 0.07128906 0.17089844 0.17382812 0.055664062 0.091308594 -0.037353516 0.049804688 -0.03930664 0.044189453 0.0625 0.048583984 -0.053222656 0.048828125 -0.13085938 -0.028930664 -0.036132812 -0.060791016 -0.057373047 0.123046875 -0.08251953 -0.0119018555 0.125 0.0013580322 0.063964844 -0.10644531 -0.14355469 -0.042236328 0.024047852 -0.16894531 -0.08886719 -0.080566406 0.064941406 0.061279297 -0.04736328 -0.05883789 -0.047607422 0.014465332 -0.0625\n",
            " 301\n",
            "for -0.011779785 -0.04736328 0.044677734 0.06347656 -0.018188477 -0.063964844 -0.0013122559 -0.072265625 0.064453125 0.08642578 -0.16992188 -0.039794922 0.07128906 -0.025878906 0.018188477 0.13671875 0.14453125 -0.033691406 -0.09765625 -0.12011719 -0.079589844 0.0625 -0.06689453 0.07421875 0.022705078 0.033447266 -0.18066406 0.052001953 0.0138549805 0.09277344 0.0035095215 -0.009094238 -0.09716797 0.067871094 -0.0087890625 0.044189453 -0.13378906 -0.099609375 0.033203125 0.027954102 0.15527344 -0.017700195 0.014282227 -0.10986328 -0.08544922 -0.07324219 -0.024658203 0.17285156 0.061767578 0.08935547 -0.024291992 0.14160156 -0.032958984 0.02746582 -0.15527344 0.007873535 -0.07080078 0.043701172 0.006011963 -0.055908203 -0.14746094 0.028442383 -0.1328125 -0.17675781 -0.091308594 -0.05078125 -0.026000977 -0.1484375 -0.080566406 0.15039062 -0.04345703 0.07910156 0.033203125 0.09033203 0.022705078 -0.0625 0.1640625 0.0859375 -0.012390137 0.19628906 -0.06225586 0.022460938 -0.030151367 0.021240234 0.003326416 -0.055419922 -0.07324219 0.029785156 0.049804688 0.017456055 0.10449219 0.03881836 0.08496094 -0.24804688 0.06933594 -0.14941406 0.05834961 0.095703125 -0.033447266 0.06298828 0.021362305 -0.14550781 0.053710938 -0.09082031 -0.025390625 0.045410156 0.0053100586 -0.115722656 -0.01953125 0.12109375 0.032226562 0.09472656 -0.064453125 0.022705078 0.12060547 0.060302734 0.12060547 0.048828125 0.09326172 0.06689453 0.029296875 -0.034179688 -0.111328125 0.053466797 -0.025634766 0.017822266 0.06225586 -0.025878906 0.14550781 0.0625 0.107910156 -0.16308594 -0.09765625 -0.10595703 -0.08544922 -0.08886719 0.10107422 -0.079589844 0.008422852 0.024047852 0.13085938 0.05126953 0.08154297 0.09375 -0.05859375 -0.09667969 -0.028320312 -0.14550781 -0.14746094 0.14550781 -0.017578125 0.032958984 -0.08544922 -0.010986328 -0.037109375 -0.013671875 0.035888672 -0.008239746 0.05029297 -0.09472656 0.047851562 0.020751953 0.030639648 0.12988281 0.052734375 0.018798828 -0.017578125 0.03491211 0.018310547 -0.009887695 -0.18457031 -0.08984375 -0.029052734 -0.060791016 -0.05126953 -0.0023651123 0.06640625 -0.08251953 -0.040039062 0.096191406 -0.15429688 -0.15332031 0.028320312 0.013122559 0.029907227 -0.012145996 -0.09667969 0.024780273 0.19335938 0.013000488 0.024169922 -0.035888672 0.09863281 -0.09667969 -0.20019531 -0.013793945 0.0859375 -0.080078125 -0.17675781 -0.17480469 0.005126953 -0.03491211 -0.0546875 0.09375 -0.09326172 -0.011962891 -0.0005645752 0.09765625 0.024780273 -0.039794922 0.009765625 0.11816406 0.025756836 0.123046875 0.064453125 0.07080078 0.029296875 -0.049560547 -0.078125 0.028930664 0.045654297 -0.04296875 0.025878906 -0.051757812 0.140625 0.004272461 -0.037841797 0.02746582 0.060058594 0.028320312 0.028076172 -0.036621094 0.13085938 -9.679794e-05 -0.06933594 -0.022094727 0.067871094 -0.02331543 -0.015319824 -0.05834961 0.061035156 0.00064468384 0.0039978027 -0.07128906 0.091796875 0.026245117 0.020019531 0.03540039 -0.057861328 -0.029663086 0.02734375 0.025146484 0.060302734 0.13183594 -0.0043640137 0.0027313232 0.059814453 0.09863281 -0.091796875 -0.045898438 -0.017456055 0.038330078 -0.019165039 0.04638672 0.047851562 0.09814453 -0.040283203 0.09423828 -0.03466797 -0.042236328 0.0703125 -0.013671875 0.10644531 0.016479492 0.13183594 -0.0016937256 -0.008483887 -0.14257812 -0.04663086 -0.10986328 0.08203125 -0.041015625 -0.018920898 0.087890625 -0.0028076172 0.23828125 -0.04711914 -0.022949219 0.040771484 0.029296875 -0.022583008 0.0037231445 -0.08251953 0.08154297 0.00793457 0.00047683716 0.018432617 0.07128906 -0.03491211 0.024169922\n",
            " 301\n",
            "that -0.01574707 -0.028320312 0.083496094 0.05029297 -0.11035156 0.03173828 -0.014221191 -0.08984375 0.11767578 0.11816406 -0.071777344 -0.07714844 -0.068847656 0.07714844 -0.13867188 0.006500244 0.010986328 -0.015136719 -0.0009613037 -0.030273438 -0.00015830994 0.038330078 -0.024169922 -0.045898438 0.09472656 -0.05517578 -0.064941406 0.0061035156 0.0008544922 0.06201172 -0.05444336 0.014099121 0.022216797 -0.044921875 0.111328125 -0.03857422 0.05126953 0.025146484 0.016967773 0.06298828 0.13769531 0.13574219 0.06542969 -0.064453125 -0.024047852 -0.013366699 -0.037109375 0.0043029785 -0.01574707 0.019042969 0.10839844 0.044677734 -0.044921875 -0.095214844 0.08691406 0.08203125 0.0068359375 -0.13183594 0.0027313232 -0.075683594 0.022460938 0.171875 -0.048583984 0.038330078 -0.088378906 -0.017211914 0.021850586 0.13378906 0.010681152 0.049804688 0.038085938 -0.0052490234 0.061279297 -0.050048828 -0.10595703 0.055664062 0.15429688 0.17089844 0.048095703 0.12695312 0.08154297 -0.1015625 0.043945312 -0.013549805 -0.13378906 -0.15722656 0.024291992 0.20898438 -0.10205078 -0.09375 0.048583984 0.07519531 0.0035247803 -0.123535156 -0.024169922 -0.0013198853 0.038330078 0.007598877 0.017700195 0.043701172 -0.09814453 -0.05810547 0.014099121 0.041015625 -0.03540039 -0.022949219 -0.13085938 -0.14453125 0.028930664 -0.122558594 -0.07128906 -0.0071411133 -0.09667969 0.05859375 0.104003906 0.026367188 0.0075683594 0.036132812 0.040283203 0.052734375 -0.20410156 -0.033447266 -0.029052734 0.03173828 -0.123535156 -0.06738281 0.01586914 -0.08642578 0.012512207 -0.06298828 -0.12060547 0.0234375 -0.13183594 -0.11816406 -0.012145996 -0.10986328 0.095214844 -0.041992188 0.018310547 0.051757812 0.014953613 -0.15917969 -0.021728516 -0.005126953 0.035888672 -0.003036499 -0.078125 -0.05126953 -0.0074157715 0.087402344 -0.023925781 0.044189453 -0.11376953 0.021484375 -0.003829956 -0.04345703 -0.104003906 -0.18554688 -0.044921875 0.044921875 -0.044433594 0.019042969 -0.020996094 0.0134887695 0.015258789 -0.030395508 0.04663086 0.10253906 -0.0138549805 0.008239746 -0.052734375 0.01965332 -0.076171875 -0.08984375 0.043945312 0.00793457 0.012634277 -0.10839844 -0.018554688 -0.10449219 -0.15234375 -0.07910156 -0.028808594 -0.018676758 0.09716797 -0.008361816 -0.03540039 0.007537842 0.05810547 0.08203125 0.028808594 0.05102539 0.0031738281 -0.018554688 0.014953613 -0.072753906 -0.034179688 0.043945312 -0.048828125 -0.16113281 0.025634766 0.036621094 -0.00015354156 -0.0012588501 -0.039794922 -0.032226562 -0.01574707 0.060791016 0.09716797 -0.015014648 -0.033691406 -0.015319824 0.0046691895 0.032958984 -0.08203125 0.10644531 0.15429688 0.0087890625 -0.12011719 0.061279297 0.05859375 0.03881836 -0.015991211 -0.043945312 0.12011719 -0.07519531 0.125 0.03515625 0.072753906 0.087402344 0.021118164 -0.07373047 0.034423828 -0.09423828 0.01159668 -0.057128906 -0.07861328 0.015991211 0.075683594 0.030517578 0.0046081543 -0.14550781 -0.024780273 -0.107910156 0.068847656 0.05810547 0.125 -0.06542969 0.005279541 0.01184082 0.06982422 0.12695312 0.06542969 -0.017333984 0.119140625 -0.032470703 0.14453125 0.076660156 -0.032226562 -0.06591797 0.06298828 -0.0625 -0.096191406 0.10644531 -0.039794922 0.11621094 -0.00970459 -0.03540039 -0.06542969 0.05883789 0.16210938 0.05126953 0.15917969 0.095214844 0.076171875 -0.091796875 0.025146484 -0.07861328 0.08935547 -0.05859375 -0.040039062 0.045898438 0.03100586 0.0390625 0.03564453 -0.10595703 -0.037109375 -0.16113281 0.021362305 0.0012207031 -0.011291504 -0.015625 -0.033447266 -0.020629883 -0.01940918 0.063964844 0.020141602 0.006866455 0.061035156 -0.1484375\n",
            " 301\n",
            "is 0.0070495605 -0.07324219 0.171875 0.022583008 -0.1328125 0.19824219 0.11279297 -0.107910156 0.071777344 0.020874023 -0.123046875 -0.05908203 0.10107422 0.0107421875 0.14355469 0.25976562 -0.036376953 0.18554688 -0.07861328 -0.022705078 -0.12060547 0.17773438 0.049560547 0.017211914 0.079589844 -0.045654297 -0.18847656 0.18945312 -0.02319336 0.06298828 0.09765625 -0.019042969 -0.07910156 0.15234375 0.17382812 0.1015625 -0.16308594 0.114746094 0.10058594 -0.09277344 0.109375 0.05883789 -0.021606445 0.06347656 0.041992188 -0.008850098 0.032226562 0.10644531 0.064453125 -0.118652344 0.030517578 0.06689453 0.12207031 -0.08300781 0.171875 0.07861328 0.095214844 -0.0077819824 0.02319336 0.0234375 -0.016845703 0.15527344 -0.10986328 -0.17675781 -0.11621094 0.0234375 -0.010620117 0.052734375 -0.13378906 0.079589844 0.07373047 0.043945312 0.115234375 -0.020629883 0.07470703 -0.0115356445 0.080566406 0.041748047 0.080078125 0.3515625 0.09667969 -0.21289062 0.16503906 -0.078125 0.06982422 -0.0013961792 -0.091308594 0.12988281 0.25195312 -0.016113281 0.09326172 -0.14648438 -0.0015106201 -0.15136719 -0.026855469 -0.15722656 0.026367188 0.0859375 0.071777344 0.07714844 -0.0390625 0.05444336 -0.12792969 0.091308594 -0.18457031 -0.037597656 -0.027954102 -0.08984375 -0.11669922 -0.09863281 0.048095703 -0.16210938 -0.10888672 0.08496094 -0.045654297 0.15820312 -0.038085938 -0.08203125 0.203125 0.08642578 0.06933594 0.032226562 -0.16015625 0.09472656 -0.024658203 0.05419922 0.027954102 0.044921875 0.16992188 0.072753906 -0.036376953 -0.010253906 -0.017089844 -0.107421875 -0.0007019043 -0.07373047 0.25390625 0.056640625 0.03515625 -0.008605957 0.18554688 0.021484375 0.26367188 -0.023803711 -0.099121094 -0.041259766 -0.06933594 -0.11376953 0.050048828 -0.05883789 0.046142578 0.087402344 0.10546875 0.10644531 0.027954102 0.09472656 0.11621094 -0.17285156 -0.03491211 -0.20800781 0.059570312 0.104003906 -0.0017929077 0.05859375 -0.029785156 -0.037597656 0.048583984 -0.063964844 0.079589844 0.06933594 -0.10498047 -0.14453125 0.04345703 -0.068847656 -0.03564453 -0.01171875 0.013671875 -0.06591797 0.119140625 0.03125 -0.04638672 -0.0019683838 0.0073547363 -0.056640625 0.027832031 0.08251953 -0.0134887695 0.071777344 0.14453125 0.12792969 0.042236328 0.14160156 -0.018066406 0.021606445 -0.091796875 0.13378906 -0.1953125 -0.05029297 -0.037841797 -0.096191406 0.103027344 -0.106933594 -0.14746094 0.099609375 -0.23046875 0.22753906 -0.07519531 0.064941406 0.091796875 0.046875 0.06298828 0.06982422 0.046142578 0.09716797 -0.20214844 0.19921875 0.18652344 -0.119628906 -0.14257812 0.15039062 -0.033691406 -0.14550781 -0.0006904602 -0.07324219 0.13378906 0.03564453 -0.022949219 0.027709961 -0.07910156 0.20703125 -0.083496094 -0.049560547 0.03149414 0.1484375 0.055664062 -0.044921875 -0.079589844 0.004760742 -0.020751953 0.060058594 0.004760742 0.011169434 0.17285156 -0.13476562 0.030761719 -0.079589844 0.09033203 0.061035156 0.07714844 -0.05029297 -0.092285156 -0.26757812 0.107910156 0.0859375 0.06298828 0.107910156 -0.026733398 0.10205078 -0.12060547 0.052978516 0.09472656 -0.16503906 0.044189453 0.072265625 0.041259766 0.42578125 -0.103027344 -0.16015625 -0.09033203 -0.063964844 -0.048095703 0.14453125 0.06542969 0.049316406 0.05419922 0.13574219 -0.01928711 -0.21582031 -0.07421875 -0.14648438 0.011474609 -0.16503906 -0.10498047 0.0032043457 0.13476562 -0.003967285 -0.103515625 -0.13964844 0.10449219 -0.012573242 -0.23339844 -0.036376953 -0.09375 0.18261719 0.02709961 0.12792969 -0.024780273 0.011230469 0.1640625 0.106933594\n",
            " 301\n",
            "on 0.026733398 -0.09082031 0.027832031 0.20410156 0.006225586 -0.09033203 0.022583008 -0.16113281 0.1328125 0.061035156 -0.01574707 0.088378906 0.013793945 0.04638672 -0.055908203 -0.06689453 0.012268066 0.13671875 0.15429688 -0.046142578 -0.03930664 -0.15429688 -0.16503906 0.107910156 0.033203125 -0.05102539 0.037109375 0.1015625 0.11035156 0.020507812 0.0067749023 0.0011825562 -0.012512207 -0.125 0.014831543 -0.026855469 -0.021484375 0.015075684 0.13867188 0.048583984 -0.076660156 -0.11669922 0.106933594 0.041748047 0.012817383 -0.009460449 -0.028930664 -0.03857422 0.24316406 0.009521484 0.022094727 0.22265625 0.009155273 -0.045410156 -0.03540039 0.140625 -0.18457031 0.07763672 0.041503906 -0.08496094 -0.099121094 0.05834961 -0.09667969 -0.20214844 -0.014038086 -0.0023651123 0.14746094 0.20019531 0.059570312 0.15429688 0.13476562 0.005279541 0.125 0.08544922 -0.027709961 -0.05810547 0.18359375 0.007873535 -0.15332031 0.12402344 -0.080078125 -0.14355469 0.14941406 0.014587402 0.107910156 -0.20117188 -0.15039062 0.052490234 0.07714844 0.091796875 -0.038085938 0.1484375 0.0546875 -0.15136719 0.014282227 -0.10498047 0.019042969 -0.06347656 0.053466797 0.03491211 0.13964844 -0.13378906 0.21679688 -0.19433594 -0.05834961 -0.13476562 -0.265625 -0.104003906 0.03540039 -0.21582031 0.08251953 0.045166016 -0.06982422 -0.04321289 0.026977539 -0.09033203 0.005493164 0.049804688 -0.03564453 0.059814453 -0.14941406 -0.022094727 -0.033203125 0.17578125 -0.06640625 -0.018310547 0.011291504 -0.042236328 -0.07714844 0.017456055 -0.10498047 -0.10449219 -0.04736328 -0.029541016 -0.061523438 -0.05078125 -0.025634766 -0.095214844 -0.08105469 -0.1015625 0.20214844 0.118652344 -0.002822876 -0.060302734 0.022460938 0.13085938 0.080566406 -0.15429688 -0.08251953 0.16015625 0.057861328 0.09765625 -0.020996094 -0.045166016 -0.07324219 0.0043640137 -0.09082031 0.019165039 -0.016601562 -0.05029297 0.014709473 -0.0041503906 0.03466797 0.057373047 0.080078125 0.006225586 0.063964844 0.024536133 0.03173828 -0.125 -0.078125 -0.024536133 -0.072265625 -0.08642578 -0.07714844 0.04345703 -0.00018787384 -0.011413574 -0.099121094 0.026245117 0.053466797 0.045410156 -0.07128906 0.13867188 0.041015625 0.011169434 -0.015319824 0.032958984 0.18261719 0.017456055 -0.031982422 0.107910156 0.032958984 -0.03515625 -0.21777344 0.10205078 -0.029296875 -0.0009460449 -0.0071411133 -0.026367188 0.061767578 -0.016967773 -0.021728516 -0.119140625 0.009094238 0.103027344 -0.0030059814 0.14941406 0.10595703 -0.040283203 -0.018432617 0.035888672 -0.038085938 0.056884766 0.015319824 0.01977539 0.18066406 0.008178711 -0.15136719 0.032226562 0.15722656 0.05078125 -0.028930664 0.043945312 -0.05859375 0.0030975342 -0.012634277 0.16113281 0.10595703 -0.033935547 0.18164062 -0.044677734 0.034179688 -0.037841797 -0.008850098 -0.036865234 0.07861328 0.02709961 0.046142578 0.068847656 0.05053711 -0.0017471313 -0.13671875 -0.15332031 0.09863281 -0.16113281 0.0066223145 -0.0859375 -0.017578125 0.040771484 0.029907227 0.011413574 -0.020263672 -0.064453125 0.017456055 -0.12890625 -0.00034713745 0.042236328 0.0032958984 0.122558594 -0.095703125 0.092285156 0.10498047 -0.12451172 0.035888672 0.14550781 -0.10546875 0.022949219 -0.008361816 0.004638672 0.21972656 -0.049560547 0.23828125 -0.05834961 0.048339844 0.060546875 -0.037353516 -0.17773438 0.044921875 -0.042236328 0.08251953 0.11035156 -0.109375 0.09423828 -0.072265625 0.049072266 -0.15820312 0.078125 0.029541016 -0.12109375 0.026855469 -0.027954102 0.030883789 0.040527344 -0.13085938 0.08300781 0.01574707 -0.11669922 -0.029418945 -0.07080078\n",
            " 301\n",
            "## 0.16894531 -0.06298828 -0.00026512146 0.06347656 0.087402344 -0.030029297 0.001449585 -0.07763672 0.19921875 -0.0017700195 -0.16699219 -0.040527344 0.024414062 0.018920898 -0.08300781 -0.055419922 0.049316406 -0.032958984 -0.16992188 0.06640625 -0.25585938 -0.203125 -0.05126953 -0.10253906 0.16308594 0.08251953 -0.0546875 0.027832031 0.14355469 0.018554688 -0.12695312 -0.19140625 -0.035888672 -0.25 -0.07763672 0.013916016 -0.060058594 0.061279297 0.10546875 0.15527344 0.037353516 0.0076293945 -0.060302734 0.12890625 0.055664062 0.01977539 0.08105469 -0.025146484 -0.08691406 0.12988281 -0.15136719 0.053222656 0.06591797 -0.0625 -0.22070312 0.05908203 -0.13671875 -0.03881836 -0.19921875 0.020385742 -0.15917969 -0.012329102 -0.06542969 -0.1328125 0.06982422 0.20898438 0.00982666 0.016479492 0.18359375 0.15917969 0.013305664 -0.0703125 0.1171875 0.05517578 0.06933594 0.01940918 -0.052246094 -0.04296875 0.09277344 0.05078125 0.088378906 -0.15625 0.014099121 0.06347656 -0.060546875 -0.08251953 -0.09375 0.026245117 0.115234375 -0.06640625 -0.064453125 0.13769531 -0.15234375 -0.10888672 -0.05126953 0.06738281 -0.034423828 0.009155273 -0.020874023 0.05908203 0.05493164 -0.007598877 -0.067871094 -0.017089844 0.0069885254 -0.15136719 0.048583984 -0.17675781 0.0009460449 -0.11035156 0.05834961 -0.091308594 -0.10644531 -0.12060547 -0.032714844 -0.061523438 0.03540039 0.087890625 0.013244629 0.059326172 -0.12597656 0.09814453 0.08300781 -0.096191406 0.14550781 -0.048583984 0.18847656 -0.0028686523 0.20507812 0.22851562 0.007507324 0.0068359375 -0.032714844 -0.10058594 -0.07763672 -0.022338867 -0.068847656 0.03881836 -0.13867188 0.15234375 -0.106933594 0.07324219 0.100097656 0.046142578 0.087890625 -0.06689453 0.10888672 0.10058594 -0.049560547 -0.119140625 0.17871094 -0.059326172 -0.080566406 -0.028808594 -0.14257812 0.13183594 0.022094727 0.060058594 -0.013916016 0.032226562 -0.047851562 0.060302734 0.1953125 0.15722656 0.07714844 0.19628906 0.064941406 0.08105469 -0.003967285 -0.16992188 -0.083984375 -0.060302734 -0.04638672 -0.18554688 -0.10107422 -0.11669922 -0.030151367 -0.01574707 0.068359375 0.004852295 -0.048828125 -0.026733398 -0.026489258 0.26757812 0.04736328 0.0010299683 0.12792969 0.08251953 0.26367188 -0.11816406 0.09814453 -0.08886719 0.045166016 -0.08886719 -0.031982422 0.072265625 0.06640625 0.15917969 -0.052978516 -0.15136719 -0.22753906 0.0029144287 0.06225586 -0.053955078 0.056396484 -0.068359375 -0.023071289 0.032226562 -0.07910156 -0.100097656 -0.0046081543 -0.035888672 0.010925293 -0.076660156 -0.09033203 0.14257812 0.05859375 -0.06933594 -0.027832031 -0.061279297 -0.14257812 -0.072265625 0.020629883 -0.025634766 0.078125 -0.11328125 -0.13476562 0.05883789 -0.08496094 -0.125 -0.05126953 -0.045654297 0.059570312 0.21191406 -0.171875 0.15820312 0.050048828 -0.14550781 -0.12695312 -0.002746582 -0.06933594 0.28125 0.125 -0.25976562 0.014953613 -0.026733398 0.10058594 -0.059814453 0.021850586 -0.038085938 0.06542969 -0.033935547 -0.14257812 0.13183594 0.203125 0.037597656 0.16113281 -0.17871094 0.031982422 -0.07324219 0.083496094 -0.096191406 -0.051757812 0.0003681183 0.16308594 -0.06347656 -0.029174805 0.08300781 -0.03125 -0.009887695 0.21582031 -0.018432617 0.107421875 -0.049072266 0.22070312 -0.0055236816 -0.25976562 0.048583984 0.049316406 -0.040039062 -0.015075684 0.024658203 -0.12158203 0.005554199 0.04345703 -0.19726562 0.0119018555 0.1796875 0.02734375 0.140625 0.021118164 0.0015258789 -0.09863281 0.056640625 -0.091308594 0.103515625 0.0023040771 0.023803711 -0.123535156 0.016357422\n",
            " 301\n",
            "The -0.17285156 0.27929688 0.106933594 -0.15820312 -0.084472656 0.05908203 0.040771484 0.0025482178 0.25976562 0.18066406 0.09765625 -0.08105469 -0.010498047 0.09814453 0.00060272217 0.07080078 -0.015625 -0.095214844 -0.08105469 -0.028686523 -0.033203125 0.16503906 0.039794922 -0.037109375 0.041015625 -0.12695312 -0.12890625 0.123535156 0.049804688 0.012573242 0.057861328 -0.008300781 -0.028320312 -0.033203125 0.16113281 0.07519531 -0.25976562 0.08935547 0.13574219 0.0046081543 -0.044189453 0.02319336 -0.10449219 -0.051513672 0.083496094 -0.020507812 -0.021728516 -0.02734375 0.16015625 0.19042969 -0.032470703 0.067871094 0.103027344 -0.25390625 0.0063476562 0.20507812 0.021118164 -0.21679688 -0.024414062 0.17089844 -0.21875 0.100097656 -0.15527344 -0.12597656 -0.038330078 -0.05419922 0.19238281 0.21777344 0.12109375 -0.026489258 0.052978516 -0.020141602 0.053466797 0.076660156 0.045654297 0.01977539 0.12451172 0.10205078 0.15234375 0.25195312 0.04296875 -0.18554688 -0.07519531 0.22753906 -0.13183594 -0.27539062 -0.20117188 0.12597656 -0.18652344 -0.13964844 -0.12597656 0.080078125 -0.033935547 -0.23730469 -0.007659912 0.28320312 -0.017211914 0.02722168 -0.234375 0.12890625 0.16796875 -0.010192871 0.06542969 -0.1328125 0.07763672 -0.11669922 0.0146484375 -0.052978516 -0.12109375 -0.099121094 0.055908203 -0.041992188 0.107421875 0.091308594 0.14746094 0.10205078 -0.0013961792 0.20117188 0.084472656 0.075683594 -0.24316406 -0.18945312 -0.07910156 -0.06640625 0.12792969 0.15039062 -0.16601562 -0.095214844 0.096191406 -0.05029297 -0.025024414 -0.049316406 -0.043701172 -0.0234375 0.06640625 -0.13378906 -0.25 -0.2421875 -0.11328125 0.026367188 0.13867188 -0.07080078 -0.22265625 -0.11279297 -0.018066406 -0.19042969 0.07421875 -0.16601562 0.006286621 0.1953125 -0.0043640137 -0.16699219 0.14746094 -0.048828125 0.1875 -0.234375 0.14453125 0.0076904297 0.041015625 -0.06738281 -0.016723633 -0.05029297 0.08496094 0.036621094 0.13476562 0.080566406 -0.044677734 0.16601562 -0.22265625 0.009338379 -0.119628906 -0.064941406 0.033447266 -0.09765625 0.0146484375 0.12158203 0.123535156 -0.13476562 -0.052978516 -0.27734375 -0.037841797 -0.07910156 -0.068847656 0.057128906 0.03112793 0.07080078 0.079589844 0.0065612793 0.14257812 -0.084472656 0.03125 -0.03564453 0.023071289 -0.016601562 -0.17285156 -0.16113281 -0.107421875 0.055664062 -0.092285156 -0.25585938 0.03930664 -0.20410156 0.08496094 0.046142578 0.012084961 -0.012573242 0.063964844 0.2578125 0.18457031 -0.055908203 0.0234375 0.10498047 0.12011719 0.009094238 -0.0056762695 0.111328125 0.15136719 0.024658203 -0.038330078 0.115722656 0.171875 -0.041259766 0.103027344 0.044677734 -0.0126953125 -0.08203125 -0.03491211 0.007873535 0.07910156 -0.00050354004 0.022460938 -0.16113281 0.11621094 0.25195312 -0.04663086 -0.080078125 -0.09863281 0.047607422 -0.060546875 0.118652344 -0.033935547 -0.06689453 -0.00077819824 -0.048828125 -0.0119018555 -0.08251953 0.21777344 -0.0018081665 0.1484375 -0.020507812 0.26367188 0.17089844 -0.04638672 0.12792969 0.048095703 -0.037597656 0.16699219 -0.19140625 0.0390625 0.07714844 -0.01586914 0.099121094 -0.15820312 -0.013793945 0.018554688 0.15527344 -0.18164062 0.033691406 -0.0008049011 0.06689453 -0.018432617 0.14160156 0.064453125 -0.0073242188 0.079589844 -0.027954102 0.125 -0.23730469 0.036376953 -0.046875 -0.046875 0.05493164 0.079589844 0.27148438 0.22558594 -0.20507812 -0.20507812 -0.064453125 -0.07763672 -0.06982422 -0.017700195 -0.12890625 0.021972656 0.014770508 -0.052978516 -0.203125 0.061767578 0.123046875 0.12988281 -0.18261719\n",
            " 301\n",
            "with -0.024902344 0.021972656 -0.03540039 0.13671875 0.016357422 -0.027954102 -0.024291992 -0.13964844 0.057373047 0.06225586 -0.11767578 -0.09716797 -0.17480469 -0.020629883 -0.119140625 0.099121094 0.060302734 0.140625 -0.06298828 -0.048828125 -0.045410156 0.034179688 0.011291504 -0.045166016 0.1953125 -0.038330078 -0.13183594 0.06347656 -0.018798828 0.1328125 0.057128906 0.022216797 -0.046875 0.09082031 -0.17578125 0.024658203 -0.048583984 0.0055236816 0.05493164 0.012023926 0.12060547 0.029785156 -0.15917969 0.09472656 -0.05444336 0.010681152 0.11328125 -0.040527344 0.24121094 0.12792969 -0.015014648 0.044921875 -0.12792969 -0.091308594 0.13964844 0.15429688 -0.08154297 0.016479492 0.038085938 -0.14160156 0.00579834 0.068359375 -0.16992188 -0.104003906 -0.09667969 0.10595703 -0.025512695 0.060791016 -0.14160156 0.17871094 0.09375 0.13574219 -0.022949219 0.05908203 0.05102539 -0.15625 0.140625 0.24414062 0.053466797 0.19433594 0.042236328 -0.12451172 -0.0077209473 -0.03857422 0.12207031 -0.1796875 -0.25585938 -0.01977539 -0.07373047 0.15039062 -0.012573242 0.06933594 -0.014160156 -0.045410156 -0.080078125 -0.09765625 0.055908203 0.018310547 -0.09375 0.16503906 0.064941406 -0.20800781 -0.140625 0.02368164 0.020263672 0.060058594 0.07470703 -0.036865234 0.026489258 -0.0024871826 0.0037231445 0.076660156 -0.04663086 -0.08105469 -0.03564453 0.19921875 0.15332031 0.07421875 0.039794922 0.06347656 -0.10644531 -0.0390625 -0.111328125 -0.021606445 -0.055419922 -0.09033203 -0.0039367676 -0.11376953 0.12402344 0.122558594 0.0546875 -0.072753906 -0.17871094 0.07128906 -0.06689453 0.030639648 -0.007751465 0.0390625 0.04321289 -0.052001953 -0.024780273 0.20410156 -0.067871094 0.036376953 0.06591797 0.03100586 0.008483887 -0.1953125 -0.0025177002 0.18457031 0.14355469 0.080566406 -0.012268066 0.07080078 -0.03112793 -0.021240234 -0.12695312 -0.18457031 0.024658203 0.08691406 -0.0048217773 0.109375 -0.055908203 0.19628906 0.057128906 0.10595703 0.07861328 -0.09423828 -0.08886719 -0.078125 -0.18945312 0.006286621 0.01159668 -0.05834961 -0.119628906 -0.09667969 -0.0063171387 0.07470703 -0.07910156 0.10546875 0.03112793 -0.014831543 0.068847656 0.032958984 -0.123046875 -0.053710938 -0.009155273 -0.057128906 0.06982422 -0.064453125 -0.0012130737 -0.050048828 -0.061523438 -0.061035156 -0.0061035156 -0.012817383 -0.13378906 0.0077209473 -0.14257812 -0.18164062 0.03491211 0.06347656 -0.031982422 -0.09375 0.030883789 -0.06738281 -0.04711914 -0.048339844 0.11669922 0.01361084 -0.029052734 -0.119628906 0.038085938 0.09326172 -0.0053710938 0.0025787354 0.043945312 0.19921875 -0.14453125 0.011474609 0.0024108887 0.10107422 0.084472656 0.009521484 -0.053466797 -0.01953125 -0.03930664 -0.055664062 0.18554688 0.016967773 0.09326172 -0.048339844 0.025390625 0.0234375 -0.029907227 -0.040527344 0.008850098 0.092285156 0.024291992 0.024169922 -0.16113281 0.15820312 0.032958984 -0.061767578 0.076171875 0.08886719 0.20117188 0.07080078 -0.07910156 0.055908203 0.0043640137 0.014892578 0.17675781 -0.007659912 -0.028808594 -0.06689453 0.08154297 -0.0107421875 -0.083496094 0.10595703 0.03881836 0.038330078 -0.03149414 0.049316406 0.023803711 0.078125 0.012390137 -0.032226562 0.06542969 0.05834961 0.13769531 -0.031982422 -0.056396484 -0.071777344 0.08544922 0.028198242 0.0020141602 -0.07080078 0.03466797 -0.040039062 -0.03125 0.08935547 -0.040283203 0.045898438 0.10986328 0.080566406 -0.087890625 -0.033203125 0.049072266 0.013977051 -0.020751953 0.0030822754 -0.13867188 -0.024414062 -0.09326172 -0.047607422 -0.075683594 0.010803223 -0.018798828 -0.068847656\n",
            " 301\n",
            "said -0.009094238 -0.044189453 0.099609375 -0.076171875 -0.056640625 0.061523438 0.25585938 -0.15820312 0.016601562 -0.09667969 -0.06347656 -0.15136719 0.07470703 0.13867188 -0.23046875 0.06225586 0.17675781 0.21679688 -0.25 -0.041992188 -0.20117188 0.048339844 0.119628906 0.027832031 0.11230469 -0.13476562 -0.109375 -0.05908203 -0.20703125 0.08251953 -0.123046875 0.04638672 0.056396484 0.032958984 0.07421875 -0.03173828 0.04296875 0.051513672 -0.15527344 -0.0016174316 -0.028686523 -0.09423828 0.079589844 -0.19824219 -0.20703125 -0.07763672 -0.115722656 -0.095214844 -0.014160156 0.15136719 0.17382812 -0.02319336 0.15234375 -0.10644531 0.05493164 0.14355469 -0.109375 0.013916016 0.11035156 -0.099121094 -0.18457031 0.045166016 -0.09472656 0.015563965 -0.028564453 0.13378906 0.042236328 0.00024318695 -0.13476562 0.18066406 -0.0859375 -0.060058594 0.13085938 0.110839844 -0.15917969 0.03857422 0.056152344 0.27929688 0.14257812 0.04736328 0.16796875 0.08251953 0.13964844 0.13085938 -0.055664062 -0.14648438 -0.15917969 0.31054688 -0.022949219 -0.044677734 0.3359375 -0.028320312 0.09277344 0.01965332 -0.055419922 -0.14648438 0.017089844 0.20800781 -0.064453125 -0.14746094 -0.11328125 -0.07470703 -0.021240234 0.122558594 0.14453125 0.06933594 -0.047851562 -0.17871094 -0.14648438 0.049316406 0.03564453 -0.119628906 0.003189087 0.020507812 -0.13671875 -0.24121094 -0.0095825195 0.03173828 0.05859375 0.08496094 -0.21484375 0.23242188 -0.059326172 0.12792969 -0.115234375 -0.20117188 0.087890625 -0.05517578 0.030151367 0.026489258 0.0134887695 -0.1328125 -0.032226562 -0.080078125 -0.014770508 -0.122558594 0.053955078 0.15136719 0.09033203 0.06738281 -0.03466797 -0.029052734 0.005340576 -0.072265625 0.0087890625 0.12792969 -0.022949219 -0.24023438 0.029174805 0.052734375 0.06738281 0.26757812 -0.119628906 0.23046875 0.064941406 0.02368164 -0.041259766 0.0012664795 -0.033691406 0.043701172 0.041503906 0.08251953 0.07373047 0.046875 0.05834961 -0.010070801 0.0029144287 -0.05053711 0.29882812 -0.056396484 0.033203125 0.09472656 0.083496094 -0.11816406 -0.02331543 -0.021728516 0.21289062 0.080078125 -0.049804688 0.19921875 0.055664062 -0.052246094 0.03955078 0.060546875 0.125 0.013549805 -0.06933594 0.14746094 0.037597656 0.14941406 -0.06738281 -0.15722656 -0.18652344 0.12207031 -0.10595703 -0.006591797 0.18066406 0.110839844 -0.171875 -0.010070801 0.08886719 -0.171875 0.064453125 -0.051513672 -0.06640625 0.083496094 0.060058594 0.040039062 -0.048828125 0.0036010742 -0.026367188 -0.018432617 0.014160156 0.0115356445 0.045410156 -0.06298828 0.10058594 0.07470703 -0.012390137 0.029296875 0.20410156 -0.12402344 -0.12890625 -0.060791016 0.19042969 -0.15625 -0.0048217773 0.23144531 0.018554688 0.06689453 0.0027770996 0.04736328 -0.10839844 -0.1484375 0.056396484 -0.0703125 0.018676758 -0.09472656 0.040771484 -0.04248047 0.059814453 0.038085938 -0.13769531 0.033935547 0.16015625 0.09863281 -0.03955078 -0.12890625 0.19042969 -0.028076172 -0.10546875 0.010498047 0.08300781 -0.03173828 0.18066406 -0.114746094 0.061767578 0.002166748 -0.03540039 -0.20019531 -0.079589844 -0.099121094 0.029663086 0.04321289 0.10058594 0.3046875 0.26953125 -0.09082031 -0.08886719 0.19433594 0.23535156 -0.20800781 0.032226562 0.018798828 -0.13867188 -0.026000977 0.01574707 -0.028686523 0.07861328 -0.115234375 -0.18164062 0.16503906 -0.115722656 -0.1171875 0.17089844 0.12597656 -0.012512207 -0.032958984 0.052246094 0.02722168 -0.19335938 0.029907227 -0.09326172 0.053710938 -0.11767578 0.06982422 0.10595703 0.14453125 0.18066406 -0.08691406\n",
            " 301\n",
            "was 0.026000977 -0.0018920898 0.18554688 -0.051757812 0.005126953 -0.10986328 -0.008178711 -0.088378906 0.09667969 0.048339844 0.011047363 -0.36328125 0.08203125 -0.021240234 0.15820312 0.044189453 -0.011779785 0.21289062 -0.057373047 0.056640625 -0.107421875 0.18554688 0.07714844 0.0001449585 0.15234375 -0.06542969 -0.15234375 0.22558594 0.08105469 0.08886719 0.07324219 -0.103515625 -0.06689453 0.17675781 0.21289062 0.140625 -0.034179688 0.017822266 0.059570312 0.0002861023 0.05883789 0.009277344 0.16699219 -0.0027008057 0.115722656 0.10449219 0.053710938 0.018554688 0.10644531 0.05053711 -0.016479492 -0.12792969 0.21679688 0.051513672 0.047851562 0.15234375 0.171875 0.07861328 -0.05883789 -0.04296875 -0.072753906 0.18164062 -0.080566406 -0.15429688 -0.11669922 0.084472656 -0.061767578 -0.045166016 0.009216309 0.13378906 0.01928711 0.064453125 0.10888672 0.15820312 -0.02355957 0.123535156 0.16992188 0.03491211 0.12988281 0.265625 0.19335938 -0.088378906 0.08496094 -0.029663086 0.057617188 0.025146484 -0.1015625 0.19921875 0.10449219 -0.024291992 0.020141602 -0.03515625 0.06640625 -0.06201172 0.029052734 -0.09814453 -0.18164062 0.21484375 -0.057617188 -0.045166016 0.044921875 -0.01953125 -0.20898438 0.119628906 -0.09033203 0.05078125 0.009033203 -0.09765625 -0.07861328 -0.13671875 -0.11376953 -0.005645752 -0.040771484 -0.0020599365 -0.056640625 0.0036468506 0.08300781 -0.07080078 0.26367188 0.12451172 -0.016113281 0.091308594 -0.23925781 -0.010498047 -0.067871094 0.140625 0.234375 -0.063964844 0.1953125 0.05029297 -0.125 0.020629883 -0.119140625 -0.1171875 -9.012222e-05 0.036865234 0.14648438 0.024780273 -0.14941406 0.003036499 -0.03100586 0.106933594 0.25585938 -0.060058594 -0.20703125 0.15820312 -0.21582031 -0.18457031 -0.17285156 0.0079956055 -0.030395508 0.09814453 0.0046691895 0.2578125 0.106933594 0.12695312 0.06347656 -0.13085938 0.06542969 -0.099121094 0.05908203 -0.037109375 0.10107422 0.15332031 -0.15332031 -0.075683594 0.05859375 -0.05053711 0.20800781 0.048583984 -0.09423828 -0.09716797 -0.123046875 -0.19726562 -0.17675781 -0.111328125 0.111328125 -0.05883789 0.22753906 0.040039062 0.12451172 0.14746094 0.018188477 0.040527344 0.16992188 0.11376953 -0.022460938 0.06738281 0.0859375 0.06738281 0.020629883 0.047851562 0.018432617 0.20507812 -0.046875 0.20019531 -0.015625 -0.140625 0.010986328 -0.17382812 0.048583984 -0.15820312 -0.10449219 0.036376953 0.030151367 0.12792969 -0.11425781 0.14160156 0.234375 -0.08984375 -0.0010299683 -0.15039062 0.1796875 0.13574219 -0.20800781 -0.012756348 0.17578125 -0.13964844 -0.203125 -0.030029297 -0.027832031 -0.006500244 0.12695312 -0.14941406 0.14648438 -0.008422852 0.11230469 0.16601562 -0.01574707 0.123046875 0.072265625 -0.043701172 -0.075683594 -0.09033203 0.1015625 -0.14453125 -0.040039062 -0.0126953125 0.026611328 -0.078125 0.03564453 0.03491211 0.1796875 -0.13867188 0.028076172 -0.028686523 0.067871094 0.0703125 0.095703125 0.050048828 -0.022094727 -0.30078125 0.11425781 0.07519531 0.012634277 0.1328125 0.025268555 0.036376953 -0.028198242 -0.13671875 0.1796875 -0.09277344 0.08496094 0.1328125 0.039794922 0.4296875 -0.018798828 -0.14746094 0.061035156 0.09033203 0.08691406 -0.068847656 0.110839844 0.09814453 0.15039062 0.16113281 -0.080566406 -0.17480469 -0.033203125 -0.12890625 0.122558594 -0.014465332 -0.16308594 -0.035888672 0.027832031 -0.06347656 -0.07910156 -0.114746094 0.018432617 0.029174805 -0.30078125 -0.045898438 -0.17480469 0.23339844 0.022583008 0.11035156 -0.103515625 -0.12158203 0.22167969 -0.021972656\n",
            " 301\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U0V-pnHMAEHh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# sum(1 for line in vocabObject)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qLQYB4EyVTAW",
        "colab_type": "text"
      },
      "source": [
        "Check WS353 Dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NT9tkJ1A9JuQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 102
        },
        "outputId": "4c4097e6-13da-4178-834b-142c439803d3"
      },
      "source": [
        "path1 = 'Evaluation_Benchmarks/Word_Similarity/WS353/wordsim_similarity_goldstandard.txt'\n",
        "path2 = 'Evaluation_Benchmarks/Word_Similarity/WS353/wordsim_relatedness_goldstandard.txt'\n",
        "path3 = 'Evaluation_Benchmarks/Word_Similarity/WS353/wordsim353_agreed.txt'\n",
        "path4 = 'Evaluation_Benchmarks/Word_Similarity/WS353/wordsim353_annotator1.txt'\n",
        "path5 = 'Evaluation_Benchmarks/Word_Similarity/WS353/wordsim353_annotator2.txt'\n",
        "WS_sim_object = open(path1,'r')\n",
        "WS_rel_object = open(path2,'r')\n",
        "WS_agreed_obj = open(path3,'r')\n",
        "WS_ann1_obj = open(path4,'r')\n",
        "WS_ann2_obj = open(path5,'r') \n",
        "count1 =count2 = count3=count4 =count5= 0 \n",
        "\n",
        "for index,line in enumerate(WS_sim_object):\n",
        "  count1+=1\n",
        "for index,line in enumerate(WS_rel_object):\n",
        "  count2+=1\n",
        "for index,line in enumerate(WS_agreed_obj):\n",
        "  if line.strip(' ').split(' ')[0] == '#':\n",
        "    #print(line)\n",
        "    continue\n",
        "  count3+=1\n",
        "for index,line in enumerate(WS_ann1_obj):\n",
        "  if line.strip(' ').split(' ')[0] == '#':\n",
        "    #print(line)\n",
        "    continue\n",
        "  count4+=1\n",
        "for index,line in enumerate(WS_ann2_obj):\n",
        "  if line.strip(' ').split(' ')[0] == '#':\n",
        "    #print(line)\n",
        "    continue\n",
        "  count5+=1      \n",
        "print(\"sim\",count1)  \n",
        "print(\"rel\",count2)\n",
        "print(\"ag\",count3)\n",
        "print(\"ann1\",count4)\n",
        "print(\"ann2\",count5)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "sim 203\n",
            "rel 252\n",
            "ag 352\n",
            "ann1 352\n",
            "ann2 352\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TZgKni3I5J5E",
        "colab_type": "text"
      },
      "source": [
        "Check SYN-REL dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hW-gFV3_KM3x",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "e25e6ba1-0afa-4983-d4d5-200765d8f97c"
      },
      "source": [
        "path_1 = 'Evaluation_Benchmarks/Syntactic_Relns/questions-words.txt'\n",
        "synrel_obj = open(path_1,'r')\n",
        "count=0\n",
        "for index, line in enumerate(synrel_obj):\n",
        "  count+=1\n",
        "print(\"total\", count)  \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 19558\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9WQovRtu6GaA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "3a861a6c-038d-4a69-d68c-58ec7855eb12"
      },
      "source": [
        "path_1 = 'Evaluation_Benchmarks/Syntactic_Relns/questions-words.txt'\n",
        "outFile_path = '/'.join(path_1.split('/')[:-1]) + '/syntactic_alone.txt'\n",
        "outFile_obj = open(outFile_path, 'w') \n",
        "\n",
        "synrel_obj1 = open(path_1,'r')\n",
        "count1=0\n",
        "flag = 0\n",
        "for index, line in enumerate(synrel_obj1):\n",
        "  if line.strip().split(' ')[0] == ':' : \n",
        "    continue\n",
        "  if flag:\n",
        "    outFile_obj.write(line.strip()+'\\n')\n",
        "  count1+=1\n",
        "\n",
        "  if count1 == 8869:\n",
        "    flag = 1\n",
        "\n",
        "outFile_obj.close()\n",
        "\n",
        "print(\"total\", count1)\n",
        "count2 =0 \n",
        "synrel_obj2 = open(outFile_path, 'r') \n",
        "for index, line in enumerate(synrel_obj2):\n",
        "  count2+= 1\n",
        "print(\"only syntactic\", count2)  \n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 19544\n",
            "only syntactic 10675\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oMx7a9-ZJEpJ",
        "colab_type": "text"
      },
      "source": [
        "Check Sentiment Analysis (SA) dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HWl7ohu98tFn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f668426a-b2c8-4b12-f4b3-945ba2f7c67f"
      },
      "source": [
        "path_1 = 'Evaluation_Benchmarks/Sentiment_Analysis/train.txt'\n",
        "sen_obj = open(path_1,'r')\n",
        "count=0\n",
        "for index, line in enumerate(sen_obj):\n",
        "  count+=1\n",
        "print(\"total\", count)  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 8544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bHpIy47LKe1h",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        },
        "outputId": "39a2387e-c55a-47f6-e4c9-68008fab5769"
      },
      "source": [
        "import math\n",
        "import numpy as np\n",
        "from numpy import dot\n",
        "from numpy.linalg import norm\n",
        "from scipy.stats import spearmanr\n",
        "from gensim.models import Word2Vec\n",
        "from gensim.models.keyedvectors import KeyedVectors\n",
        "\n",
        "\n",
        "def word_similarity_tasks(word_vec=None):\n",
        "  \"\"\"\n",
        "  Compute Spearman's Correlation Coefficient for each of the 3 tasks for the given word_vec.\n",
        "\n",
        "  Parameters\n",
        "  ----------\n",
        "  word_vec : dict\n",
        "    A dictionary with keys as words and values as vectors.\n",
        "\n",
        "  Returns\n",
        "  -------\n",
        "  arg1 : float\n",
        "    Spearman's Correlation Coefficient for WS-353 task.\n",
        "  arg2 : float\n",
        "    Spearman's Correlation Coefficient for RG-65 task.\n",
        "  arg3 : float\n",
        "    Spearman's Correlation Coefficient for MEN task.\n",
        "  \"\"\"\n",
        "\n",
        "  # Task 1: WS-353\n",
        "  # print('Working on WS_353...')\n",
        "  path_to_dataset = 'Evaluation_Benchmarks/Word_Similarity/WS353_Exact/EN-WS-353-ALL.txt'\n",
        "  WS_353 = open(path_to_dataset,'r')\n",
        "  sim_score_true = []\n",
        "  sim_score_vecs = []\n",
        "  missed_count=0\n",
        "  for index, line in enumerate(WS_353):\n",
        "    line = line.strip().lower().split()\n",
        "    sim_score =float(line[2])\n",
        "    sim_score_true.append(sim_score/10)\n",
        "\n",
        "    word_pair = (line[0], line[1])\n",
        "    try: # If word vectors exist for both words.\n",
        "      a = word_vec[word_pair[0]]\n",
        "      b = word_vec[word_pair[1]]\n",
        "      cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    except: # If there is no word vector for either of the words.\n",
        "      missed_count+=1\n",
        "      cos_sim = 0\n",
        "    sim_score_vecs.append(cos_sim)\n",
        "  if missed_count>0:print('Missed in WS353:', missed_count)\n",
        "\n",
        "  WS_353_spearman = spearmanr(sim_score_true, sim_score_vecs)[0]\n",
        "  # print('Spearman coefficient :', WS_353_spearman)\n",
        "\n",
        "  # Task 2: RG-65\n",
        "  # print('Working on RG_65...')\n",
        "  path_to_dataset = 'Evaluation_Benchmarks/Word_Similarity/RG65/EN-RG-65.txt'\n",
        "  RG_65 = open(path_to_dataset,'r')\n",
        "  sim_score_true = []\n",
        "  sim_score_vecs = []\n",
        "  missed_count=0\n",
        "  for index, line in enumerate(RG_65):\n",
        "    line = line.strip().lower().split()\n",
        "    sim_score =float(line[2])\n",
        "    sim_score_true.append(sim_score/10)\n",
        "\n",
        "    word_pair = (line[0], line[1])\n",
        "    try: # If word vectors exist for both words.\n",
        "      a = word_vec[word_pair[0]]\n",
        "      b = word_vec[word_pair[1]]\n",
        "      cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    except: # If there is no word vector for either of the words.\n",
        "      missed_count+=1\n",
        "      cos_sim = 0\n",
        "    sim_score_vecs.append(cos_sim)\n",
        "  if missed_count>0:print('Missed in RG65:', missed_count)\n",
        "\n",
        "  RG_65_spearman = spearmanr(sim_score_true, sim_score_vecs)[0]\n",
        "  # print('Spearman coefficient :', RG_65_spearman)\n",
        "\n",
        "  # Task 3: MEN\n",
        "  # print('Working on MEN...')\n",
        "  path_to_dataset = 'Evaluation_Benchmarks/Word_Similarity/MEN/EN-MEN-TR-3k.txt'\n",
        "  MEN = open(path_to_dataset,'r')\n",
        "  sim_score_true = []\n",
        "  sim_score_vecs = []\n",
        "  missed_count=0\n",
        "  for index, line in enumerate(MEN):\n",
        "    line = line.strip().lower().split()\n",
        "    sim_score =float(line[2])\n",
        "    sim_score_true.append(sim_score/50)\n",
        "\n",
        "    word_pair = (line[0], line[1])\n",
        "    try: # If word vectors exist for both words.\n",
        "      a = word_vec[word_pair[0]]\n",
        "      b = word_vec[word_pair[1]]\n",
        "      cos_sim = dot(a, b)/(norm(a)*norm(b))\n",
        "    except: # If there is no word vector for either of the words.\n",
        "      missed_count+=1\n",
        "      cos_sim = 0\n",
        "    sim_score_vecs.append(cos_sim)\n",
        "  if missed_count>0:print('Missed in MEN:', missed_count)\n",
        "\n",
        "  MEN_spearman = spearmanr(sim_score_true, sim_score_vecs)[0]\n",
        "  # print('Spearman coefficient :', MEN_spearman)\n",
        "\n",
        "  return WS_353_spearman, RG_65_spearman, MEN_spearman\n",
        "\n",
        "''' Read all the word vectors and normalize them '''\n",
        "def read_word_vecs(filename):\n",
        "  wordVectors = {}\n",
        "  # if filename.endswith('.gz'): fileObject = gzip.open(filename, 'r')\n",
        "  fileObject = open(filename, 'r')\n",
        "  # print('Read file..')\n",
        "  for index,line in enumerate(fileObject):\n",
        "    # if index%50000==0:print('->', index,'/ 3000000')\n",
        "    line = line.strip().lower()\n",
        "    word = line.split()[0]\n",
        "    wordVectors[word] = np.zeros(len(line.split())-1, dtype=float)\n",
        "    # if len(line.split()) != 301:\n",
        "      # print('-'*50,index, word)\n",
        "      # continue\n",
        "    for index, vecVal in enumerate(line.split()[1:]):\n",
        "      wordVectors[word][index] = float(vecVal)\n",
        "    ''' normalize weight vector '''\n",
        "    wordVectors[word] /= math.sqrt((wordVectors[word]**2).sum() + 1e-6)\n",
        "    \n",
        "  # sys.stderr.write(\"Vectors read from: \"+filename+\" \\n\")\n",
        "  return wordVectors\n",
        "\n",
        "\n",
        "# word_vec_filenames = ['Vector Representation of Words/1/glove.6B.300d.txt','Vector Representation of Words/2/GoogleNews-vectors-negative300.txt','Vector Representation of Words/3/3_word_vectors.txt']\n",
        "word_vec_filenames = ['Vector Representation of Words/3/3_word_vectors.txt']\n",
        "\n",
        "print('Word Vector\\t\\t WS-353\\t\\t RG-65\\t\\t MEN')\n",
        "for filename in word_vec_filenames:\n",
        "  word_vec = read_word_vecs(filename)\n",
        "  # word_vec = KeyedVectors.load_word2vec_format('Vector Representation of Words/2/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "  WS_353_spearman, RG_65_spearman, MEN_spearman = word_similarity_tasks(word_vec)\n",
        "  print(filename.split('/')[-1][:20],'\\t','%.4f' %(WS_353_spearman),'\\t','%.4f' %(RG_65_spearman),'\\t','%.4f' %(MEN_spearman))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Word Vector\t\t WS-353\t\t RG-65\t\t MEN\n",
            "Missed in MEN: 1\n",
            "3_word_vectors.txt \t 0.6258 \t 0.6299 \t 0.3140\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BEb5RQc_VuGN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 164
        },
        "outputId": "9b90e2b7-7d9f-4736-80e5-e15f7a7f9af6"
      },
      "source": [
        "from gensim.models import Word2Vec\n",
        "from gensim.test.utils import datapath\n",
        "from gensim.test.utils import datapath, get_tmpfile\n",
        "from gensim.models import KeyedVectors\n",
        "from gensim.scripts.glove2word2vec import glove2word2vec\n",
        "\n",
        "word_vec_bin = KeyedVectors.load_word2vec_format('Vector Representation of Words/2/GoogleNews-vectors-negative300.bin', binary=True)\n",
        "word_vec_bin.evaluate_word_pairs(datapath('wordsim353.tsv'))\n",
        "# word_vec = Word2Vec.load_word2vec_format(filename, binary=False)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((0.6238773466616107, 1.7963237724171284e-39),\n",
              " SpearmanrResult(correlation=0.6589215888009288, pvalue=2.5346056459149263e-45),\n",
              " 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EclzHAe5V7nU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "bc184b11-d3f0-4457-e456-514b2a1cddb8"
      },
      "source": [
        "lengths = []\n",
        "for _, i in word_vec.items():\n",
        "  lengths.append(len(i))\n",
        "print(np.mean(lengths))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "50.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/usr/local/lib/python3.6/dist-packages/gensim/test/test_data/wordsim353.tsv'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FzOyHihOBWmd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 219
        },
        "outputId": "41322f8c-45e2-487c-a33c-99b670a40570"
      },
      "source": [
        "\n",
        "# glove_file = 'Vector Representation of Words/3/3_word_vectors.txt'\n",
        "# tmp_file = 'Vector Representation of Words/3/temp.txt'\n",
        "\n",
        "# _ = glove2word2vec(glove_file, tmp_file)\n",
        "# model = KeyedVectors.load_word2vec_format(tmp_file)\n",
        "model.evaluate_word_pairs(datapath('wordsim353.tsv')),word_vec_bin.evaluate_word_pairs(datapath('wordsim353.tsv'))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/smart_open/smart_open_lib.py:410: UserWarning: This function is deprecated, use smart_open.open instead. See the migration notes for details: https://github.com/RaRe-Technologies/smart_open/blob/master/README.rst#migrating-to-the-new-open-function\n",
            "  'See the migration notes for details: %s' % _MIGRATION_NOTES_URL\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(((0.6139829092144378, 5.950038844375029e-38),\n",
              "  SpearmanrResult(correlation=0.625762577349116, pvalue=9.08944637013904e-40),\n",
              "  0.0),\n",
              " ((0.6238773466616107, 1.7963237724171284e-39),\n",
              "  SpearmanrResult(correlation=0.6589215888009288, pvalue=2.5346056459149263e-45),\n",
              "  0.0))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4e4ngAerRxfv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}