{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"toefl.ipynb","provenance":[],"collapsed_sections":[],"machine_shape":"hm"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"code","metadata":{"id":"e7c5nq9Dsfne","colab_type":"code","outputId":"c9ff8e92-1f7b-4b48-f3d4-5bfb08b99d6c","executionInfo":{"status":"ok","timestamp":1586197180157,"user_tz":-330,"elapsed":26038,"user":{"displayName":"PAWAN PRASAD K me16b179","photoUrl":"","userId":"14049130637097040281"}},"colab":{"base_uri":"https://localhost:8080/","height":139}},"source":["from google.colab import drive\n","drive.mount('/gdrive')\n","%cd /gdrive"],"execution_count":2,"outputs":[{"output_type":"stream","text":["Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n","\n","Enter your authorization code:\n","··········\n","Mounted at /gdrive\n","/gdrive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"_J5ISIdasl2z","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":272},"outputId":"0165e305-9c0f-487e-9b99-fe502fea0a65","executionInfo":{"status":"ok","timestamp":1586197185374,"user_tz":-330,"elapsed":4525,"user":{"displayName":"PAWAN PRASAD K me16b179","photoUrl":"","userId":"14049130637097040281"}}},"source":["import os\n","import numpy as np\n","from sklearn.metrics.pairwise import cosine_similarity\n","from gensim.models import KeyedVectors\n","from tqdm.notebook import tqdm\n","import math\n","os.chdir('/gdrive/My Drive/NLP_Project_Programs/Paper_Implementation')\n","os.listdir()"],"execution_count":3,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['Vector Representation of Words',\n"," 'lexicons',\n"," 'Evaluation_Benchmarks',\n"," 'retrofit.ipynb',\n"," '__pycache__',\n"," 'retrofit.py',\n"," 'Retrofitted_WordVecs.ipynb',\n"," 'toefl_2.ipynb',\n"," 'Check Retrofitted Google Vecs.ipynb',\n"," 'Retrofitted_WordVecs Google_Debug.ipynb',\n"," 'Skip_Gram_Retrofit+All_Benchmark.ipynb',\n"," 'SynRelns.ipynb',\n"," 'Word Similarity Tasks.ipynb',\n"," 'Sentiment Analysis.ipynb',\n"," 'toefl.ipynb']"]},"metadata":{"tags":[]},"execution_count":3}]},{"cell_type":"code","metadata":{"id":"6gyeM9Qeswtp","colab_type":"code","colab":{}},"source":["path = 'Evaluation_Benchmarks/Synonym_Selection_TOEFL/toefl.txt'  # path to TOEFL evaluation dataset file\n","obj = open(path,'r')\n","list_questions = []\n","list_choices = []\n","list_true_ind = []\n","\n","\n","for i,line in enumerate(obj):\n","  line = line.strip().lower().split()\n","  list_questions.append(line[0])\n","  list_choices.append(line[2:])\n","  list_true_ind.append(int(line[1])) \n","\n","\n","def toefl_func(words, vectors, vector_dimensions):\n","  \"\"\"\n","  Computes accuracy for the task of selecting the semantically closest word to a target from a list of four candidates using cosine similarity\n","\n","  Parameters\n","  ----------\n","  words : list\n","    A list containing only words (dtype = string) from given word vector file\n","\n","  vectors : list\n","    A list of lists with each sub-list as vector (dtype = float) for corresponding word from given word vector file  \n","\n","  vector_dimensions : int \n","    The length of the vectors present in given word-vector file\n","\n","  Returns\n","  -------\n","  arg1 : float\n","    accuracy score for the evaluation task\n","  \"\"\"\n","  count = 0\n","  accuracy = 0\n","  missed_count = 0\n","  mean_vector = np.mean(vectors, axis=0)\n","  \n","  for question, choices, ans in tqdm(zip(list_questions,list_choices,list_true_ind)):\n","    mat = np.zeros((5,vector_dimensions))\n","    \n","    for i in range(5):\n","      mat[i,:] = mean_vector\n","    for word,vector in zip(words, vectors):\n","      if question == word:\n","        mat[0,:] = vector\n","      if choices[0] == word:\n","        mat[1,:] = vector\n","      if choices[1] == word:\n","        mat[2,:] = vector\n","      if choices[2] == word:\n","        mat[3,:] = vector\n","      if choices[3] == word:\n","        mat[4,:] = vector\n","\n","    temp_bool = mat == 0\n","    if np.sum(temp_bool[1,:])==vector_dimensions:\n","      # print('Missed Word :', choices[0])\n","      missed_count+=1\n","      continue\n","    if np.sum(temp_bool[2,:])==vector_dimensions:\n","      # print('Missed Word :', choices[1])\n","      missed_count+=1\n","      continue\n","    if np.sum(temp_bool[3,:])==vector_dimensions:\n","      # print('Missed Word :', choices[2])\n","      missed_count+=1\n","      continue\n","    if np.sum(temp_bool[4,:])==vector_dimensions:\n","      # print('Missed Word :', choices[2])\n","      missed_count+=1\n","      continue\n","\n","    a1 = mat[1:,:].reshape(4,vector_dimensions)\n","    a2 = mat[0,:].reshape(1,vector_dimensions)\n","    '''--------------------- FOR DEBUGGING ------------------------'''\n","    # print(question, choices[0], choices[1], choices[2], choices[3])\n","    # print(a1, a2)\n","    # print(np.shape(a1), np.shape(a2))\n","    # break\n","    ind = np.argmax(cosine_similarity(a1,a2))\n","    '''--------------------- FOR DEBUGGING ------------------------'''\n","    #print(question, choices)\n","    #print(ind, ans, cosine_similarity(a1,a2))\n","    #print('-'*25)\n","\n","    if ind == ans:\n","      # print(question, choices, ans, cosine_similarity(a1,a2))\n","      count += 1    \n","  \n","  print('Missed Words/Questions :', missed_count)\n","  accuracy = count/len(list_questions)  \n","\n","  return accuracy"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"8ROEDLP3ccs_","colab_type":"code","colab":{}},"source":["#Global Context word vectors file\n","WordVec_path_a = 'Vector Representation of Words/3/3_word_vectors.txt'\n","#Skip Gram (SG) word vectors file\n","WordVec_path_b = 'Vector Representation of Words/2/GoogleNews-vectors-negative300.bin'\n","#Glove word vector file\n","WordVec_path_c = 'Vector Representation of Words/1/glove.6B.300d.txt'\n","\n","#Global Context retrofitted word vectors file\n","outfile_path_a1 = 'Vector Representation of Words/3/RETRO_FrameNet_3_word_vectors.txt' \n","outfile_path_a2 = 'Vector Representation of Words/3/RETRO_ppdb-xl_3_word_vectors.txt' \n","outfile_path_a3 = 'Vector Representation of Words/3/RETRO_wordnet-synonyms_3_word_vectors.txt' \n","outfile_path_a4 = 'Vector Representation of Words/3/RETRO_wordnet-synonyms+_3_word_vectors.txt' \n","\n","#Glove retrofitted word vector files\n","outfile_path_c1 = 'Vector Representation of Words/1/RETRO_FrameNet_glove.6B.300d.txt'\n","outfile_path_c2 = 'Vector Representation of Words/1/RETRO_ppdb-xl_glove.6B.300d.txt'\n","outfile_path_c3 = 'Vector Representation of Words/1/RETRO_wordnet-synonyms_glove.6B.300d.txt'\n","outfile_path_c4 = 'Vector Representation of Words/1/RETRO_wordnet-synonyms+_glove.6B.300d.txt'\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"bq3k-tuuwJk5","colab_type":"code","colab":{}},"source":["'''Evaluating on the Glove and GC word vectors file (including retrofitted Glove and GC word vectors)'''\n","\n","''' Read all the word vectors and normalize them '''\n","def read_word_vecs(filename,vector_dimensions):\n","  # Use this for Glove and Global Context Vectors\n","  words = []\n","  vectors = []\n","  fileObject = open(filename, 'r')\n","  for index,line in tqdm(enumerate(fileObject)):\n","    # if index%50000==0:print('->', index,'/ 3000000')\n","    line = line.strip().lower().split()\n","    words.append(line[0])\n","    # if len(line)-1 != vector_dimensions: continue\n","    vec = np.zeros(len(line)-1, dtype=float)\n","    if vec.shape[0] != vector_dimensions: \n","      #print('Skipping at index :', index)\n","      continue\n","    for ind, vecVal in enumerate(line[1:]):\n","      vec[ind] = float(vecVal)\n","    ''' normalize weight vector '''\n","    vec /= math.sqrt((vec**2).sum() + 1e-6)\n","    vectors.append(vec)\n","    \n","  return words, vectors\n","\n","''' change 2nd argument inside tuple to 50 or 300 accordingly for Global context (50) and Glove word vector files respectively '''   \n","filenames = [(outfile_path_a4,50), (outfile_path_c4,300)]  \n","\n","for filename in filenames:\n","  words,vectors = read_word_vecs(filename[0],filename[1])\n","  print('word vec generated for :', filename)\n","  accuracy_score= toefl_func(words,vectors,vector_dimensions=filename[1])\n","  print('Accuracy :',accuracy_score)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"xVBcmdY8tbrZ","colab_type":"code","colab":{}},"source":["'''Evaluating on the SG (skip gram) word vectors file (does not include retrofitted SG word vectors)'''\n","\n","filename = WordVec_path_b \n","def read_word_vectors_skipgram():\n","  # Use this for Google skipgram word2vec model\n","  word_vec_bin = KeyedVectors.load_word2vec_format(filename, binary=True)\n","  return word_vec_bin\n","\n","## function to convert word_vec to (words, vectors)\n","def my_function(word_vec):\n","  words = []\n","  vectors = []\n","  vocabulary = word_vec.vocab\n","  for word in tqdm(vocabulary):\n","      words.append(word)  \n","      vectors.append(word_vec[word])\n","  \n","  return words, vectors    \n","\n","word_vec_bin = read_word_vectors_skipgram()\n","words, vectors = my_function(word_vec_bin)\n","print('word vec generated for :', filename)\n","accuracy_score = toefl_func(words,vectors,300)\n","print('Accuracy :',accuracy_score)\n"],"execution_count":0,"outputs":[]}]}